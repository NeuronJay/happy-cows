# Data Wrangling

This document is intended to outline the data gathering and cleansing processes utilized in this project.  

## Data set: Weather

### Acquisition

The weather data set consists of daily summaries of weather measurements for Franklin County, Pennsylvania such as low temperature, high temperature, and total precipitation [[Example File]](/references/example_files/weather_example.csv).  The CSV files were requested from the [NOAA Online Climate Data Online Search](https://www.ncdc.noaa.gov/cdo-web/search) for full calendar year 2014, 2015, and 2016, and then again for all available data in 2017.  The resulting CSV files were uploaded to AWS S3 to be programmatically retrieved by the script [get_data.py](/scripts/get_data.py).

In order to clean the weather data, the full files are processed by the script [parse_weather.py](/scripts/parse_weather.py).  Initially, the resulting DataFrame was limited to a smaller set of variables including the station identifier, name of station, latitude, longitude, elevation, date, volume of precipitation, maximum temperature and minimum temperature.  The resulting DataFrame was reindexed to a unique combination of station identifer and date (parsed to a date time object from a string), as row represents daily summary from a single station.  Null values were permitted in the precipitation, minimum temperature, and maximum temperature columns and interpreted as measurements not taken by a specific station.  Assumed ranges were applied to the precipitation (assumed to between 0 and 20 inches if not null) and temperature columns (assumed to be between -20 and 120 degrees if not null).  After asserting numerical ranges, the remaining columns were checked for the expected data types.  The resulting DataFrame was stored in a local database through the [load_database.py](/scripts/load_database.py)

## Data set: Milk Production

The milk volume data set consists of daily system logs in a series of text files from the local storage of the dairy farm's DeLaval - ALPROâ„¢ herd management system [[Example File]](/references/example_files/milk_volume_example.txt).  These system logs consist of individual lines, each with a time stamp, and associated records.  After retrieval of the raw files from AWS s3 [[script]](/scripts/get_data.py) In order to extract relevant data, first the text files were parsed into a single column DataFrame where each row consists of the contents of each individual line line.  The resulting DataFrame rows were selected that matched the regex pattern to include lines such as the following:

``` txt
04:27:56	R	200	Cow	Duration1	3:47
04:27:56	R	200	Cow	AverFlow1	3.8
04:27:56	R	200	Cow	PeakFlow1	5.0
04:27:56	R	200	Cow	MilkToday1	14.8
```

The lines above suggest that Cow #200 produced 14.8 pounds of milk, in 3:47 with an average flow rate of 3.8 lb/min and a peak flow of 5.0 lb/min.  In addition this record was captured at 4:27:56 am.  Additional manipulations and assertions were applied in the [parse_milk_volume.py](/scripts/parse_milk_volume.py) to produce a DataFrame with a row for each individual milk volume record.  Null values were dropped that indicate that an animal had not produced milk on that occasion.  The resulting DataFrame was stored in a local database in the [load_database.py](/scripts/load_database.py)

## Data set: Animal Classification

ToDo